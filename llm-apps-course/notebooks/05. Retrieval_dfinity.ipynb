{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/llm-apps-course/notebooks/03.%20Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{llmapps-retrieval} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Retrieval Question Answering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq rich openai tiktoken wandb langchain unstructured tabulate pdf2image chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from pathlib import Path\n",
    "import tiktoken\n",
    "from getpass import getpass\n",
    "from rich.markdown import Markdown\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need an OpenAI API key to run this notebook. You can get one [here](https://platform.openai.com/account/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "\n",
    "[LangChain](https://docs.langchain.com/docs/) is a framework for developing applications powered by language models. We will use some of its features in the code below. Let's start by configuring W&B tracing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a single line of code to start tracing langchain with W&B\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
    "\n",
    "# wandb documentation to configure wandb using env variables\n",
    "# https://docs.wandb.ai/guides/track/advanced/environment-variables\n",
    "# here we are configuring the wandb project name\n",
    "os.environ[\"WANDB_PROJECT\"] = \"llmapps\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing documents\n",
    "\n",
    "We will use a small sample of markdown documents in this notebook. Let's find them and make sure we can stuff them into the prompt. That means they may need to be chunked and not exceed some number of tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"text-davinci-003\"\n",
    "# MODEL_NAME = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "def find_md_files(directory):\n",
    "    \"Find all markdown files in a directory and return a LangChain Document\"\n",
    "    dl = DirectoryLoader(directory, \"**/*.md\")\n",
    "    return dl.load()\n",
    "\n",
    "documents = find_md_files('../dfinity_md/')\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to count tokens in the documents, and for that we need the tokenizer\n",
    "tokenizer = tiktoken.encoding_for_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1372, 2423, 248, 1560, 996]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to count the number of tokens in each document\n",
    "def count_tokens(documents):\n",
    "    token_counts = [len(tokenizer.encode(document.page_content)) for document in documents]\n",
    "    return token_counts\n",
    "\n",
    "count_tokens(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `LangChain` built in `MarkdownTextSplitter` to split the documents into sections. Actually splitting `Markdown` without breaking syntax is not that easy. This splitter strips out syntax.\n",
    "- We can pass the `chunk_size` param and avoid lenghty chunks.\n",
    "- The `chunk_overlap` param is useful so you don't cut sentences randomly. This is less necessary with `Markdown`\n",
    "\n",
    "The `MarkdownTextSplitter` also takes care of removing double line breaks and save us some tokens that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 261)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "\n",
    "md_text_splitter = MarkdownTextSplitter(chunk_size=1000)\n",
    "document_sections = md_text_splitter.split_documents(documents)\n",
    "len(document_sections), max(count_tokens(document_sections))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's look at the first section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of document_sections: 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Module 4: Autonomous Governance                                                                                    \n",
       "\n",
       "In this module, you will build upon your work from modules 2 and 3 by implementing a \"governance\" canister that    \n",
       "will act as the decentralized arbiter of our auction platform's feature upgrades.                                  \n",
       "\n",
       "Background                                                                                                         \n",
       "\n",
       "Refer to our section on Autonomous Canisters in Module 1 for a quick intro to this topic.                          \n",
       "\n",
       "We ultimately want to create an automated canister that allows stakeholders to propose changes to our App.mo file. \n",
       "The governance canister enables these stakeholders to then vote on open proposals and will automatically migrate   \n",
       "App.mo and replace it with the new, proposed file. This enables us to create an \"autonomous\" system by which edits \n",
       "are suggested and then voted upon, ensuring that stakeholders will have a guaranteed say in the process if         \n",
       "initially given that power.                                                                                        \n",
       "\n",
       "Your Task                                                                                                          \n",
       "\n",
       "We have provided you with starter code in Governor.mo - your job is to finish implementing all necessary methods   \n",
       "such that we have a functional governance canister.                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Module 4: Autonomous Governance                                                                                    \n",
       "\n",
       "In this module, you will build upon your work from modules 2 and 3 by implementing a \"governance\" canister that    \n",
       "will act as the decentralized arbiter of our auction platform's feature upgrades.                                  \n",
       "\n",
       "Background                                                                                                         \n",
       "\n",
       "Refer to our section on Autonomous Canisters in Module 1 for a quick intro to this topic.                          \n",
       "\n",
       "We ultimately want to create an automated canister that allows stakeholders to propose changes to our App.mo file. \n",
       "The governance canister enables these stakeholders to then vote on open proposals and will automatically migrate   \n",
       "App.mo and replace it with the new, proposed file. This enables us to create an \"autonomous\" system by which edits \n",
       "are suggested and then voted upon, ensuring that stakeholders will have a guaranteed say in the process if         \n",
       "initially given that power.                                                                                        \n",
       "\n",
       "Your Task                                                                                                          \n",
       "\n",
       "We have provided you with starter code in Governor.mo - your job is to finish implementing all necessary methods   \n",
       "such that we have a functional governance canister.                                                                \n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"number of document_sections: {len(document_sections)}\")\n",
    "\n",
    "Markdown(document_sections[0].page_content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Let's now use embeddings with a vector database retriever to find relevant documents for a query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# We will use the OpenAIEmbeddings to embed the text, and Chroma to store the vectors\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(document_sections, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a retriever from the db now, we can pass the `k` param to get the most relevant sections from the similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs=dict(k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"How can I share my  report with my team members in a public W&B project?\"\n",
    "query = \"What are the steps required to complete the methods: 'auctionItem' and 'makeBid'\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"05. Retrieval_dfinity.ipynb\"\n",
    "docs = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dfinity_md/module-2.md\n",
      "../dfinity_md/module-2.md\n",
      "../dfinity_md/module-2.md\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Main.mo                                                                                                            \n",
       "\n",
       "main.mo has one function, setup, which calls the constructors of the relevant canisters needed to create the entire\n",
       "application - namely, we need to establish a Balances canister to store balances, an App canister to control the   \n",
       "actual process of creating and managing auctions,  and a Governor to control the governance structure for automated\n",
       "upgrades.                                                                                                          \n",
       "\n",
       "Specification                                                                                                      \n",
       "\n",
       "Task: Complete the implementation of the auctionItem and makeBid methods in App.mo.                                \n",
       "\n",
       "auctionItem creates a new Auction and adds it to the auctions list                                                 \n",
       "\n",
       "Use the name, description, and url parameters are used to create a new Item (by calling the makeItem helper        \n",
       "function defined below).                                                                                           \n",
       "\n",
       "Use this item to create a new auction, using the makeAuction helper, and finally add this auction to our auctions  \n",
       "hash map using a unique id.                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Main.mo                                                                                                            \n",
       "\n",
       "main.mo has one function, setup, which calls the constructors of the relevant canisters needed to create the entire\n",
       "application - namely, we need to establish a Balances canister to store balances, an App canister to control the   \n",
       "actual process of creating and managing auctions,  and a Governor to control the governance structure for automated\n",
       "upgrades.                                                                                                          \n",
       "\n",
       "Specification                                                                                                      \n",
       "\n",
       "Task: Complete the implementation of the auctionItem and makeBid methods in App.mo.                                \n",
       "\n",
       "auctionItem creates a new Auction and adds it to the auctions list                                                 \n",
       "\n",
       "Use the name, description, and url parameters are used to create a new Item (by calling the makeItem helper        \n",
       "function defined below).                                                                                           \n",
       "\n",
       "Use this item to create a new auction, using the makeAuction helper, and finally add this auction to our auctions  \n",
       "hash map using a unique id.                                                                                        \n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the results\n",
    "for doc in docs:\n",
    "    print(doc.metadata[\"source\"])\n",
    "    \n",
    "Markdown(docs[0].page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff Prompt\n",
    "\n",
    "We'll now take the content of the retrieved documents, stuff them into prompt template along with the query, and pass into an LLM to obtain the answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "prompt = PROMPT.format(context=context, question=query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use langchain to call openai chat API with the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">For the 'auctionItem' method, the steps required are to create a new item using the name, description and url      \n",
       "parameters, create a new auction using the makeAuction helper, and add the auction to the auctions hash map using a\n",
       "unique id. For the 'makeBid' method, the steps required are to check that the bidder has enough money in their     \n",
       "balance, retrieve the auction stored at the auctionId, check that the new bid amount is greater than the auction's \n",
       "current bid, and update the corresponding Auction accordingly.                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "For the 'auctionItem' method, the steps required are to create a new item using the name, description and url      \n",
       "parameters, create a new auction using the makeAuction helper, and add the auction to the auctions hash map using a\n",
       "unique id. For the 'makeBid' method, the steps required are to check that the bidder has enough money in their     \n",
       "balance, retrieve the auction stored at the auctionId, check that the new bid amount is greater than the auction's \n",
       "current bid, and update the corresponding Auction accordingly.                                                     \n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "response = llm.predict(prompt)\n",
    "Markdown(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Langchain\n",
    "\n",
    "Langchain gives us tools to do this efficiently in few lines of code. Let's do the same using `RetrievalQA` chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the steps required to complete the methods: 'auctionItem' and 'makeBid'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To complete the 'auctionItem' method, you need to use the name, description, and url parameters to create a new    \n",
       "Item, create a new Auction using the makeAuction helper, and add this auction to the auctions hash map using a     \n",
       "unique id. To complete the 'makeBid' method, you need to check that the bidder has enough money in their balance to\n",
       "make the specified bid, retrieve the auction stored at auctionId, check that the new bid amount is greater than the\n",
       "auction's current bid, and update the corresponding Auction accordingly. Finally, you need to return #ok() if the  \n",
       "bid is valid, or one of the corresponding error variants if the bid is invalid.                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "To complete the 'auctionItem' method, you need to use the name, description, and url parameters to create a new    \n",
       "Item, create a new Auction using the makeAuction helper, and add this auction to the auctions hash map using a     \n",
       "unique id. To complete the 'makeBid' method, you need to check that the bidder has enough money in their balance to\n",
       "make the specified bid, retrieve the auction stored at auctionId, check that the new bid amount is greater than the\n",
       "auction's current bid, and update the corresponding Auction accordingly. Finally, you need to return #ok() if the  \n",
       "bid is valid, or one of the corresponding error variants if the bid is invalid.                                    \n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "print(query)\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
    "result = qa.run(query)\n",
    "\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
